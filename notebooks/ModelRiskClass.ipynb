{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "# Modeling Risk Classification\n",
    "Author: Ainesh Pandey\n",
    "\n",
    "In this notebook, we will train and tune several different multi-class modeling approaches to categorize projects into one of the risk classifications generated in the [GenerateRiskTarget notebook](GenerateRiskTarget.ipynb). As a quick reminder, the risk classifications generated are as follows:\n",
    "- `Risk Class 0`: Technical Execution Risk\n",
    "- `Risk Class 1`: Managerial Process Risk\n",
    "- `Risk Class 2`: Operational Cost Risk\n",
    "\n",
    "## Table of Contents\n",
    "[Step 1: Import Packages and Data](#step-1) <br>\n",
    "[Step 2: Helper Functions for Modeling](#step-2) <br>\n",
    "[Step 3: Prototyping Baseline Solution](#step-3) <br>\n",
    "[Step 4: Testing Augmented Inputs](#step-4) <br>\n",
    "[Step 5: Results and Saving Models to Project](#step-5) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"step-1\"></a>\n",
    "\n",
    "## Import Packages and Data\n",
    "\n",
    "### Packages\n",
    "\n",
    "We start by importing the required packages for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# basic data science packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn packages for data preparation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# imblearn packages for handling unbalanced data\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "\n",
    "# modeling packages\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import itertools\n",
    "\n",
    "# visualization packages\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# package to save models to project\n",
    "import pickle\n",
    "\n",
    "# import custom preprocessing functions that we wrote in utils.py\n",
    "from scripts.utils import preprocess_string_pro, preprocess_string_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "We import `lessons_learned.csv` and keep all of the data. After some exploratory data analysis, we'll choose which features we will keep as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson(s) Learned</th>\n",
       "      <th>Recommendation(s)</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Date Lesson Occurred</th>\n",
       "      <th>Driving Event</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Project / Program</th>\n",
       "      <th>The related NASA policy(s), standard(s), handbook(s), procedure(s) or other rules</th>\n",
       "      <th>NASA Mission Directorate(s)</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>From what phase of the program or project was this lesson learned captured?</th>\n",
       "      <th>Where (other lessons, presentations, publications, etc.)?</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "      <td>The purpose of this lesson is to highlight the...</td>\n",
       "      <td>Approach 1 made it difficult to understand the...</td>\n",
       "      <td>Projects should consider RBI's risk management...</td>\n",
       "      <td>LaRC</td>\n",
       "      <td>04/05/2018</td>\n",
       "      <td>Throughout the project, it was repeatedly dete...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiation Budget Instrument</td>\n",
       "      <td>Langley Management System Center Procedure LMS...</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Implementation</td>\n",
       "      <td>LaRC Institutional Knowledge Management (IKM) ...</td>\n",
       "      <td>07/23/2021</td>\n",
       "      <td>Procurement, Small Business &amp; Industrial Relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "      <td>Early indications show that the commercial spa...</td>\n",
       "      <td>As a result of many years of expensive lessons...</td>\n",
       "      <td>As commercial vehicles and other NASA vehicles...</td>\n",
       "      <td>NESC</td>\n",
       "      <td>02/28/2021</td>\n",
       "      <td>NASA has found that the commercial spacecraft ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Space Shuttle Program, Commercial Crewed Space...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Exploration and Operations</td>\n",
       "      <td>Public</td>\n",
       "      <td>Implementation » Phase E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/23/2021</td>\n",
       "      <td>Flight Equipment, Ground Operations, Hardware,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "      <td>Trace contaminants in high-purity hydrazine (H...</td>\n",
       "      <td>There was an unexpectedly wide variation in el...</td>\n",
       "      <td>The recommendations to prevent this lesson fro...</td>\n",
       "      <td>NESC</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>Hypergolic propellants (e.g., hydrazine (N2H4)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All NASA missions using high purity hydrazine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Exploration and Operations, Science, Spa...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/23/2021</td>\n",
       "      <td>Ground Operations, Launch Vehicle, Parts, Mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "      <td>During the Radiological Control Center (RADCC)...</td>\n",
       "      <td>If possible, the design phase of both systems ...</td>\n",
       "      <td>Design phase should incorporate both design te...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>03/15/2020</td>\n",
       "      <td>The RADCC AV system controls and routes variou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiological Control Center (RADCC)</td>\n",
       "      <td>NPR 7120.7A NASA Information Technology Progra...</td>\n",
       "      <td>Human Exploration and Operations</td>\n",
       "      <td>Public</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/01/2021</td>\n",
       "      <td>Engineering Design, Integration and Testing, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>Copper Tube Pinch Failure</td>\n",
       "      <td>While pinching copper tubes is a standard prac...</td>\n",
       "      <td>The pinch was initially visually inspected and...</td>\n",
       "      <td>Have pinch tool operator perform several pract...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/17/2020</td>\n",
       "      <td>A copper tube was pinched as a test for the Ma...</td>\n",
       "      <td>Inverted metallography image of separated pinc...</td>\n",
       "      <td>Mass Spectrometer observing lunar operations (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Exploration and Operations, Space Techno...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Implementation » Phase D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/10/2020</td>\n",
       "      <td>Engineering Design, Integration and Testing, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID                                              Title  \\\n",
       "0      30004  Relationship of Government and Contractor Risk...   \n",
       "1      30101  Cable Harness Wiring and Connector Anomalies C...   \n",
       "2      29801  Best Practices for the Elemental Profiling of ...   \n",
       "3      29702  Integration and Dependency Between Different A...   \n",
       "4      29103                          Copper Tube Pinch Failure   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  The purpose of this lesson is to highlight the...   \n",
       "1  Early indications show that the commercial spa...   \n",
       "2  Trace contaminants in high-purity hydrazine (H...   \n",
       "3  During the Radiological Control Center (RADCC)...   \n",
       "4  While pinching copper tubes is a standard prac...   \n",
       "\n",
       "                                   Lesson(s) Learned  \\\n",
       "0  Approach 1 made it difficult to understand the...   \n",
       "1  As a result of many years of expensive lessons...   \n",
       "2  There was an unexpectedly wide variation in el...   \n",
       "3  If possible, the design phase of both systems ...   \n",
       "4  The pinch was initially visually inspected and...   \n",
       "\n",
       "                                   Recommendation(s) Organization  \\\n",
       "0  Projects should consider RBI's risk management...         LaRC   \n",
       "1  As commercial vehicles and other NASA vehicles...         NESC   \n",
       "2  The recommendations to prevent this lesson fro...         NESC   \n",
       "3  Design phase should incorporate both design te...          KSC   \n",
       "4  Have pinch tool operator perform several pract...          KSC   \n",
       "\n",
       "  Date Lesson Occurred                                      Driving Event  \\\n",
       "0           04/05/2018  Throughout the project, it was repeatedly dete...   \n",
       "1           02/28/2021  NASA has found that the commercial spacecraft ...   \n",
       "2           12/14/2020  Hypergolic propellants (e.g., hydrazine (N2H4)...   \n",
       "3           03/15/2020  The RADCC AV system controls and routes variou...   \n",
       "4           10/17/2020  A copper tube was pinched as a test for the Ma...   \n",
       "\n",
       "                                            Evidence  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Inverted metallography image of separated pinc...   \n",
       "\n",
       "                                   Project / Program  \\\n",
       "0                        Radiation Budget Instrument   \n",
       "1  Space Shuttle Program, Commercial Crewed Space...   \n",
       "2  All NASA missions using high purity hydrazine ...   \n",
       "3                Radiological Control Center (RADCC)   \n",
       "4  Mass Spectrometer observing lunar operations (...   \n",
       "\n",
       "  The related NASA policy(s), standard(s), handbook(s), procedure(s) or other rules  \\\n",
       "0  Langley Management System Center Procedure LMS...                                  \n",
       "1                                                NaN                                  \n",
       "2                                                NaN                                  \n",
       "3  NPR 7120.7A NASA Information Technology Progra...                                  \n",
       "4                                                NaN                                  \n",
       "\n",
       "                         NASA Mission Directorate(s) Sensitivity  \\\n",
       "0  Aeronautics Research, Human Exploration and Op...      Public   \n",
       "1                   Human Exploration and Operations      Public   \n",
       "2  Human Exploration and Operations, Science, Spa...      Public   \n",
       "3                   Human Exploration and Operations      Public   \n",
       "4  Human Exploration and Operations, Space Techno...      Public   \n",
       "\n",
       "  From what phase of the program or project was this lesson learned captured?  \\\n",
       "0                                     Implementation                            \n",
       "1                           Implementation » Phase E                            \n",
       "2                                     Not Applicable                            \n",
       "3                                      Not Specified                            \n",
       "4                           Implementation » Phase D                            \n",
       "\n",
       "  Where (other lessons, presentations, publications, etc.)? Publish Date  \\\n",
       "0  LaRC Institutional Knowledge Management (IKM) ...          07/23/2021   \n",
       "1                                                NaN          07/23/2021   \n",
       "2                                                NaN          06/23/2021   \n",
       "3                                                NaN          06/01/2021   \n",
       "4                                                NaN          12/10/2020   \n",
       "\n",
       "                                              Topics  \n",
       "0  Procurement, Small Business & Industrial Relat...  \n",
       "1  Flight Equipment, Ground Operations, Hardware,...  \n",
       "2  Ground Operations, Launch Vehicle, Parts, Mate...  \n",
       "3  Engineering Design, Integration and Testing, S...  \n",
       "4  Engineering Design, Integration and Testing, M...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lessons = pd.read_csv('../Risky Space Business Challenge Files/lessons_learned.csv', encoding='cp1252')\n",
    "\n",
    "display(df_lessons.shape)\n",
    "df_lessons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will import `risk_classifications.csv`, which we created in [GenerateRiskTarget.ipynb](GenerateRiskTarget.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Risk Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1308</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID  Risk Class\n",
       "0       1308           2\n",
       "1        616           0\n",
       "2       1307           2\n",
       "3        304           2\n",
       "4        437           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_riskclasses = pd.read_csv('../data/risk_classifications.csv')\n",
    "\n",
    "display(df_riskclasses.shape)\n",
    "df_riskclasses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine both dataframes into a master dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson(s) Learned</th>\n",
       "      <th>Recommendation(s)</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Date Lesson Occurred</th>\n",
       "      <th>Driving Event</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Project / Program</th>\n",
       "      <th>The related NASA policy(s), standard(s), handbook(s), procedure(s) or other rules</th>\n",
       "      <th>NASA Mission Directorate(s)</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>From what phase of the program or project was this lesson learned captured?</th>\n",
       "      <th>Where (other lessons, presentations, publications, etc.)?</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Risk Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "      <td>The purpose of this lesson is to highlight the...</td>\n",
       "      <td>Approach 1 made it difficult to understand the...</td>\n",
       "      <td>Projects should consider RBI's risk management...</td>\n",
       "      <td>LaRC</td>\n",
       "      <td>04/05/2018</td>\n",
       "      <td>Throughout the project, it was repeatedly dete...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiation Budget Instrument</td>\n",
       "      <td>Langley Management System Center Procedure LMS...</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Implementation</td>\n",
       "      <td>LaRC Institutional Knowledge Management (IKM) ...</td>\n",
       "      <td>07/23/2021</td>\n",
       "      <td>Procurement, Small Business &amp; Industrial Relat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "      <td>Early indications show that the commercial spa...</td>\n",
       "      <td>As a result of many years of expensive lessons...</td>\n",
       "      <td>As commercial vehicles and other NASA vehicles...</td>\n",
       "      <td>NESC</td>\n",
       "      <td>02/28/2021</td>\n",
       "      <td>NASA has found that the commercial spacecraft ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Space Shuttle Program, Commercial Crewed Space...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Exploration and Operations</td>\n",
       "      <td>Public</td>\n",
       "      <td>Implementation » Phase E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/23/2021</td>\n",
       "      <td>Flight Equipment, Ground Operations, Hardware,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "      <td>Trace contaminants in high-purity hydrazine (H...</td>\n",
       "      <td>There was an unexpectedly wide variation in el...</td>\n",
       "      <td>The recommendations to prevent this lesson fro...</td>\n",
       "      <td>NESC</td>\n",
       "      <td>12/14/2020</td>\n",
       "      <td>Hypergolic propellants (e.g., hydrazine (N2H4)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All NASA missions using high purity hydrazine ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Exploration and Operations, Science, Spa...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/23/2021</td>\n",
       "      <td>Ground Operations, Launch Vehicle, Parts, Mate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "      <td>During the Radiological Control Center (RADCC)...</td>\n",
       "      <td>If possible, the design phase of both systems ...</td>\n",
       "      <td>Design phase should incorporate both design te...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>03/15/2020</td>\n",
       "      <td>The RADCC AV system controls and routes variou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiological Control Center (RADCC)</td>\n",
       "      <td>NPR 7120.7A NASA Information Technology Progra...</td>\n",
       "      <td>Human Exploration and Operations</td>\n",
       "      <td>Public</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/01/2021</td>\n",
       "      <td>Engineering Design, Integration and Testing, S...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>Copper Tube Pinch Failure</td>\n",
       "      <td>While pinching copper tubes is a standard prac...</td>\n",
       "      <td>The pinch was initially visually inspected and...</td>\n",
       "      <td>Have pinch tool operator perform several pract...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/17/2020</td>\n",
       "      <td>A copper tube was pinched as a test for the Ma...</td>\n",
       "      <td>Inverted metallography image of separated pinc...</td>\n",
       "      <td>Mass Spectrometer observing lunar operations (...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Exploration and Operations, Space Techno...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Implementation » Phase D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/10/2020</td>\n",
       "      <td>Engineering Design, Integration and Testing, M...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID                                              Title  \\\n",
       "0      30004  Relationship of Government and Contractor Risk...   \n",
       "1      30101  Cable Harness Wiring and Connector Anomalies C...   \n",
       "2      29801  Best Practices for the Elemental Profiling of ...   \n",
       "3      29702  Integration and Dependency Between Different A...   \n",
       "4      29103                          Copper Tube Pinch Failure   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  The purpose of this lesson is to highlight the...   \n",
       "1  Early indications show that the commercial spa...   \n",
       "2  Trace contaminants in high-purity hydrazine (H...   \n",
       "3  During the Radiological Control Center (RADCC)...   \n",
       "4  While pinching copper tubes is a standard prac...   \n",
       "\n",
       "                                   Lesson(s) Learned  \\\n",
       "0  Approach 1 made it difficult to understand the...   \n",
       "1  As a result of many years of expensive lessons...   \n",
       "2  There was an unexpectedly wide variation in el...   \n",
       "3  If possible, the design phase of both systems ...   \n",
       "4  The pinch was initially visually inspected and...   \n",
       "\n",
       "                                   Recommendation(s) Organization  \\\n",
       "0  Projects should consider RBI's risk management...         LaRC   \n",
       "1  As commercial vehicles and other NASA vehicles...         NESC   \n",
       "2  The recommendations to prevent this lesson fro...         NESC   \n",
       "3  Design phase should incorporate both design te...          KSC   \n",
       "4  Have pinch tool operator perform several pract...          KSC   \n",
       "\n",
       "  Date Lesson Occurred                                      Driving Event  \\\n",
       "0           04/05/2018  Throughout the project, it was repeatedly dete...   \n",
       "1           02/28/2021  NASA has found that the commercial spacecraft ...   \n",
       "2           12/14/2020  Hypergolic propellants (e.g., hydrazine (N2H4)...   \n",
       "3           03/15/2020  The RADCC AV system controls and routes variou...   \n",
       "4           10/17/2020  A copper tube was pinched as a test for the Ma...   \n",
       "\n",
       "                                            Evidence  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Inverted metallography image of separated pinc...   \n",
       "\n",
       "                                   Project / Program  \\\n",
       "0                        Radiation Budget Instrument   \n",
       "1  Space Shuttle Program, Commercial Crewed Space...   \n",
       "2  All NASA missions using high purity hydrazine ...   \n",
       "3                Radiological Control Center (RADCC)   \n",
       "4  Mass Spectrometer observing lunar operations (...   \n",
       "\n",
       "  The related NASA policy(s), standard(s), handbook(s), procedure(s) or other rules  \\\n",
       "0  Langley Management System Center Procedure LMS...                                  \n",
       "1                                                NaN                                  \n",
       "2                                                NaN                                  \n",
       "3  NPR 7120.7A NASA Information Technology Progra...                                  \n",
       "4                                                NaN                                  \n",
       "\n",
       "                         NASA Mission Directorate(s) Sensitivity  \\\n",
       "0  Aeronautics Research, Human Exploration and Op...      Public   \n",
       "1                   Human Exploration and Operations      Public   \n",
       "2  Human Exploration and Operations, Science, Spa...      Public   \n",
       "3                   Human Exploration and Operations      Public   \n",
       "4  Human Exploration and Operations, Space Techno...      Public   \n",
       "\n",
       "  From what phase of the program or project was this lesson learned captured?  \\\n",
       "0                                     Implementation                            \n",
       "1                           Implementation » Phase E                            \n",
       "2                                     Not Applicable                            \n",
       "3                                      Not Specified                            \n",
       "4                           Implementation » Phase D                            \n",
       "\n",
       "  Where (other lessons, presentations, publications, etc.)? Publish Date  \\\n",
       "0  LaRC Institutional Knowledge Management (IKM) ...          07/23/2021   \n",
       "1                                                NaN          07/23/2021   \n",
       "2                                                NaN          06/23/2021   \n",
       "3                                                NaN          06/01/2021   \n",
       "4                                                NaN          12/10/2020   \n",
       "\n",
       "                                              Topics  Risk Class  \n",
       "0  Procurement, Small Business & Industrial Relat...           1  \n",
       "1  Flight Equipment, Ground Operations, Hardware,...           0  \n",
       "2  Ground Operations, Launch Vehicle, Parts, Mate...           1  \n",
       "3  Engineering Design, Integration and Testing, S...           2  \n",
       "4  Engineering Design, Integration and Testing, M...           2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master = df_lessons.merge(df_riskclasses, on='Lesson ID', how='inner')\n",
    "\n",
    "display(df_master.shape)\n",
    "df_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"step-2\"></a>\n",
    "\n",
    "## Helper Functions for Data Prep and Modeling\n",
    "\n",
    "There are many repetitive steps during data prep and modeling. Here, we will define helper functions to carry out those tasks.\n",
    "\n",
    "### Data Preparation Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create_pca_representation()\n",
    "\n",
    "We start with the `create_pca_representation()` function, which will take our preprocessed descriptions, convert them into TF-IDF vectors, and then convert them using PCA into the format needed for further analysis. This function will also return the vectorizers used for both TF-IDF and PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pca_representation(description_col, type):\n",
    "    if type=='prototype':\n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range = (1, 2), min_df = 5, max_df=0.5, preprocessor=preprocess_string_pro,\n",
    "                                           stop_words = 'english', strip_accents='unicode', lowercase=True)\n",
    "    elif type=='augmented':\n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range = (1, 2), min_df = 5, max_df=0.5, preprocessor=preprocess_string_aug,\n",
    "                                           stop_words = 'english', strip_accents='unicode', lowercase=True)\n",
    "    pca_vectorizer = PCA(n_components=100, random_state=5)\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(description_col)\n",
    "    tfidf_df     = pd.DataFrame(tfidf_matrix.todense())\n",
    "    pca_matrix   = pca_vectorizer.fit_transform(tfidf_df)\n",
    "\n",
    "    return pca_matrix, tfidf_vectorizer, pca_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split_data()\n",
    "\n",
    "Next, we will write the `split_data()` function, which will use __imblearn__ package's `OneSidedSelection()` function and __sklearn__ package's `train_test_split()` function to split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    X = df.drop(['Lesson ID', 'Risk Class'], axis=1)\n",
    "    y = df['Risk Class']\n",
    "\n",
    "    X, y = OneSidedSelection(random_state=5).fit_resample(X, y)\n",
    "    return train_test_split(X, y, test_size=0.10, stratify=y, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Helper Functions\n",
    "\n",
    "#### custom scorer\n",
    "\n",
    "Our model tuning will be based on the F1-score metric. However, because our problem is multi-class, we need to specify the _average_ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(f1_score, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_logisticregression_tuned()\n",
    "\n",
    "The first model we will try to run is a standard `LogisticRegression` model, tuned for the following parameters:\n",
    "- *solver*: the algorithm to use in the optimization problem\n",
    "- *penalty*: the norm of the penalty\n",
    "- *C*: regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_logisticregression_tuned(X_train, y_train, X_test, y_test):\n",
    "    # create parameter grid to fine-tune model\n",
    "    param_grid = {\n",
    "        'solver': ['newton-cg', 'lbfgs'],\n",
    "        'penalty': ['none', 'l2'],\n",
    "        'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "    # run the cross-validated grid search to identify the best parameters for the model\n",
    "    CV_lm = GridSearchCV(estimator=LogisticRegression(class_weight='balanced', random_state=5),\n",
    "                         scoring=scorer, param_grid=param_grid, n_jobs=-1, verbose=0).fit(X_train, y_train)\n",
    "\n",
    "    # print(CV_lm.cv_results_['mean_test_score'])\n",
    "\n",
    "    # extract the best parameters, as selected by the grid search\n",
    "    best_params = CV_lm.best_params_\n",
    "    best_solver = best_params['solver']\n",
    "    best_penalty = best_params['penalty']\n",
    "    best_C = best_params['C']\n",
    "    print(best_params)\n",
    "\n",
    "    # create the final LogisticRegression\n",
    "    best_lm = LogisticRegression(class_weight='balanced', random_state=5,\n",
    "                                solver=best_solver,\n",
    "                                penalty=best_penalty,\n",
    "                                C=best_C).fit(X_train, y_train)\n",
    "    lm_pred = best_lm.predict(X_test)\n",
    "\n",
    "    # track other related model performance metrics\n",
    "    lm_metrics = classification_report(y_test, lm_pred, digits=3)\n",
    "    \n",
    "    # return the model and the confusion matrix\n",
    "    return best_lm, lm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_randomforestclassifier_tuned()\n",
    "\n",
    "The next model we will try to run is a `RandomForestClassifier` model, tuned for the following parameters:\n",
    "- *n_estimators*: the number of trees in the forest\n",
    "- *max_features*: the number of features to consider when looking for the best split\n",
    "- *max_depth*: the maximum depth of each tree\n",
    "- *criterion*: the function to measure the quality of a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_randomforestclassifier_tuned(X_train, y_train, X_test, y_test):\n",
    "    # create parameter grid to fine-tune model\n",
    "    param_grid = { \n",
    "        'n_estimators': range(100, 400, 100),\n",
    "        'max_features': ['auto', 'log2', 0.25, 0.33, 0.5],\n",
    "        'max_depth' : [None, 5, 8],\n",
    "        'criterion' : ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    # get balanced sample weights\n",
    "    sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "\n",
    "    # run the cross-validated grid search to identify the best parameters for the model\n",
    "    CV_rfc = GridSearchCV(estimator=RandomForestClassifier(class_weight='balanced', random_state=5), scoring=scorer,\n",
    "                        param_grid=param_grid, n_jobs=-1, verbose=2).fit(X_train, y_train, sample_weight=sample)\n",
    "\n",
    "    # extract the best parameters, as selected by the grid search\n",
    "    best_params = CV_rfc.best_params_\n",
    "    best_n_estimators = best_params['n_estimators']\n",
    "    best_max_features = best_params['max_features']\n",
    "    best_max_depth = best_params['max_depth']\n",
    "    best_criterion = best_params['criterion']\n",
    "    print(best_params)\n",
    "\n",
    "    # create the final RandomForestClassifier\n",
    "    best_rfc = RandomForestClassifier(class_weight='balanced', random_state=5,\n",
    "                                    max_features=best_max_features,\n",
    "                                    n_estimators=best_n_estimators,\n",
    "                                    max_depth=best_max_depth,\n",
    "                                    criterion=best_criterion).fit(X_train, y_train, sample_weight=sample)\n",
    "    rfc_pred = best_rfc.predict(X_test)\n",
    "\n",
    "    # track other related model performance metrics\n",
    "    rfc_metrics = classification_report(y_test, rfc_pred, digits=3)\n",
    "\n",
    "    # return the model and the confusion matrix\n",
    "    return best_rfc, rfc_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_lgbmclassifier_tuned()\n",
    "\n",
    "The next model we will try to run is a `LGBMClassifier` model, tuned for the following parameters:\n",
    "- *max_depth*: maximum tree depth for base learners, <=0 means no limit\n",
    "- *num_leaves*: maximum tree leaves for base learners\n",
    "- *reg_alpha*: L1 regularization term on weights\n",
    "- *reg_lambda*: L2 regularization term on weights\n",
    "- *min_split_gain*: minimum loss reduction required to make a further partition on a leaf node of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lgbmclassifier_tuned(X_train, y_train, X_test, y_test):\n",
    "    # create parameter grid to fine-tune model\n",
    "    param_grid = {\n",
    "        'max_depth': [15, 20, -1],\n",
    "        'num_leaves': [10, 20, 30],\n",
    "        'reg_alpha': [0, 0.5, 1.0],\n",
    "        'reg_lambda': [0, 0.5, 1.0],\n",
    "        'min_split_gain': [0, 0.2, 0.4]\n",
    "    }\n",
    "\n",
    "    # run the cross-validated grid search to identify the best parameters for the model\n",
    "    CV_lgb = GridSearchCV(estimator=LGBMClassifier(class_weight='balanced', random_state=5), scoring=scorer,\n",
    "                        param_grid=param_grid, n_jobs=-1, verbose=2).fit(X_train, y_train)\n",
    "\n",
    "    # extract the best parameters, as selected by the grid search\n",
    "    best_params = CV_lgb.best_params_\n",
    "    best_max_depth = best_params['max_depth']\n",
    "    best_num_leaves = best_params['num_leaves']\n",
    "    best_reg_alpha = best_params['reg_alpha']\n",
    "    best_reg_lambda = best_params['reg_lambda']\n",
    "    best_min_split_gain = best_params['min_split_gain']\n",
    "    print(best_params)\n",
    "\n",
    "    # create the final LGBMClassifier\n",
    "    best_lgb = LGBMClassifier(class_weight='balanced', random_state=5,\n",
    "                            max_depth=best_max_depth,\n",
    "                            num_leaves=best_num_leaves,\n",
    "                            reg_alpha=best_reg_alpha,\n",
    "                            reg_lambda=best_reg_lambda,\n",
    "                            min_split_gain=best_min_split_gain).fit(X_train, y_train)\n",
    "    lgb_pred = best_lgb.predict(X_test)\n",
    "\n",
    "    # track other related model performance metrics\n",
    "    lgb_metrics = classification_report(y_test, lgb_pred, digits=3)\n",
    "\n",
    "    # return the model and the confusion matrix\n",
    "    return best_lgb, lgb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_knnclassifier_tuned()\n",
    "\n",
    "The next model we will try to run is a `KNeighborsClassifier` model, tuned for the following parameters:\n",
    "- *n_neighbors*: number of neighbors\n",
    "- *weights*: weight function used in prediction\n",
    "- *algorithm*: algorithm used to compute the nearest neighbors\n",
    "- *p*: power parameter for the Minkowski metric (1=L1, 2=L2, 3=L_3 for Minkowski)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_knnclassifier_tuned(X_train, y_train, X_test, y_test):\n",
    "    # create parameter grid to fine-tune model\n",
    "    param_grid = {\n",
    "        'n_neighbors': [1, 3, 5],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "    # run the cross-validated grid search to identify the best parameters for the model\n",
    "    CV_knn = GridSearchCV(estimator=KNeighborsClassifier(), scoring=scorer,\n",
    "                        param_grid=param_grid, n_jobs=-1, verbose=2).fit(X_train, y_train)\n",
    "\n",
    "    # extract the best parameters, as selected by the grid search\n",
    "    best_params = CV_knn.best_params_\n",
    "    best_n_neighbors = best_params['n_neighbors']\n",
    "    best_weights = best_params['weights']\n",
    "    best_algorithm = best_params['algorithm']\n",
    "    best_p = best_params['p']\n",
    "    print(best_params)\n",
    "\n",
    "    # create the final KNeighborsClassifier\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_n_neighbors,\n",
    "                            weights=best_weights,\n",
    "                            algorithm=best_algorithm,\n",
    "                            p=best_p).fit(X_train, y_train)\n",
    "    knn_pred = best_knn.predict(X_test)\n",
    "\n",
    "    # track other related model performance metrics\n",
    "    knn_metrics = classification_report(y_test, knn_pred, digits=3)\n",
    "\n",
    "    # return the model and the confusion matrix\n",
    "    return best_knn, knn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_gnbclassifier_tuned()\n",
    "\n",
    "The final model we will try to run is a `GaussianNB` model, tuned for the following parameters:\n",
    "- *var_smoothing*: portion of the largest variance of all features that is added to variances for calculation stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "def model_gnbclassifier_tuned(X_train, y_train, X_test, y_test):\n",
    "    # create parameter grid to fine-tune model\n",
    "    param_grid = {\n",
    "        'var_smoothing': np.logspace(0,-9, num=20)\n",
    "    }\n",
    "\n",
    "    # get balanced sample weights\n",
    "    sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "\n",
    "    # run the cross-validated grid search to identify the best parameters for the model\n",
    "    CV_gnb = GridSearchCV(estimator=GaussianNB(), scoring=scorer,\n",
    "                          param_grid=param_grid, n_jobs=-1, verbose=2).fit(X_train, y_train, sample_weight=sample)\n",
    "\n",
    "    # extract the best parameters, as selected by the grid search\n",
    "    best_params = CV_gnb.best_params_\n",
    "    best_var_smoothing = best_params['var_smoothing']\n",
    "    print(best_params)\n",
    "\n",
    "    # create the final GaussianNB classifier\n",
    "    best_gnb = GaussianNB(var_smoothing=best_var_smoothing).fit(X_train, y_train, sample_weight=sample)\n",
    "    gnb_pred = best_gnb.predict(X_test)\n",
    "\n",
    "    # track other related model performance metrics\n",
    "    gnb_metrics = classification_report(y_test, gnb_pred, digits=3)\n",
    "\n",
    "    # return the model and the confusion matrix\n",
    "    return best_gnb, gnb_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom_ensemble()\n",
    "\n",
    "We will create custom ensemble models, combining the efforts of various selected models using the `VotingClassifier` package. We will identify the best combination of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ensemble(estimators, num_ensembled, X_train, y_train, X_test, y_test):\n",
    "    best_ensemble = None\n",
    "    best_metrics = None\n",
    "    best_f1 = 0\n",
    "\n",
    "    for estimators_combo in itertools.combinations(estimators, num_ensembled):\n",
    "        # create a custom ensemble of all of the provided classifiers\n",
    "        np.random.seed(50)\n",
    "        ensemble = VotingClassifier(estimators_combo, voting='soft')\n",
    "\n",
    "        #fit model to training data\n",
    "        ensemble.fit(X_train, y_train)\n",
    "        pred = ensemble.predict(X_test)\n",
    "\n",
    "        # update best model if this outperforms previous best model\n",
    "        f1 = f1_score(y_test, pred, average='weighted')\n",
    "        if(f1 > best_f1):\n",
    "            best_ensemble = ensemble\n",
    "            best_metrics = classification_report(y_test, pred, digits=3)\n",
    "            best_f1 = f1\n",
    "\n",
    "    # return the best model, predictions, and model metrics\n",
    "    return best_ensemble, best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"step-3\"></a>\n",
    "\n",
    "## Prototyping Baseline Solution\n",
    "\n",
    "The problem at hand is a classification task; we want to use data available about projects before their execution to predict what class of risk they are likely to fall under. Therefore, we intend to generate a text-based description of each project, carry out basic NLP transformations to convert the descriptions into tabular data, and utilize several different multi-class classification algorithms to try to accurately predict which class of risk each project is likely to fall under.\n",
    "\n",
    "### Prep Dataframe for Prototyping\n",
    "\n",
    "We will create a prototype of the classification model using just the _Title_ and _Abstract_. Depending on the performance of the model, we may augment the inputs with other features as needed.\n",
    "\n",
    "First, we need to drop all irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Risk Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "      <td>The purpose of this lesson is to highlight the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "      <td>Early indications show that the commercial spa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "      <td>Trace contaminants in high-purity hydrazine (H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "      <td>During the Radiological Control Center (RADCC)...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>Copper Tube Pinch Failure</td>\n",
       "      <td>While pinching copper tubes is a standard prac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID                                              Title  \\\n",
       "0      30004  Relationship of Government and Contractor Risk...   \n",
       "1      30101  Cable Harness Wiring and Connector Anomalies C...   \n",
       "2      29801  Best Practices for the Elemental Profiling of ...   \n",
       "3      29702  Integration and Dependency Between Different A...   \n",
       "4      29103                          Copper Tube Pinch Failure   \n",
       "\n",
       "                                            Abstract  Risk Class  \n",
       "0  The purpose of this lesson is to highlight the...           1  \n",
       "1  Early indications show that the commercial spa...           0  \n",
       "2  Trace contaminants in high-purity hydrazine (H...           1  \n",
       "3  During the Radiological Control Center (RADCC)...           2  \n",
       "4  While pinching copper tubes is a standard prac...           2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prototyping = df_master[['Lesson ID', 'Title', 'Abstract', 'Risk Class']]\n",
    "\n",
    "display(df_prototyping.shape)\n",
    "df_prototyping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine the _Title_ and _Abstract_ into one block of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Risk Class</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>1</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>0</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>2</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>2</td>\n",
       "      <td>Copper Tube Pinch Failure While pinching coppe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID  Risk Class                                        Description\n",
       "0      30004           1  Relationship of Government and Contractor Risk...\n",
       "1      30101           0  Cable Harness Wiring and Connector Anomalies C...\n",
       "2      29801           1  Best Practices for the Elemental Profiling of ...\n",
       "3      29702           2  Integration and Dependency Between Different A...\n",
       "4      29103           2  Copper Tube Pinch Failure While pinching coppe..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Title' in df_prototyping.columns:\n",
    "    df_prototyping['Description'] = df_prototyping['Title'].astype(str) + ' ' + df_prototyping['Abstract'].astype(str)\n",
    "    df_prototyping.drop(['Title', 'Abstract'], axis=1, inplace=True)\n",
    "\n",
    "display(df_prototyping.shape)\n",
    "df_prototyping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do our usual data preprocessing steps and extract a PCA representation of each _Description_ using our `create_pca_representation()` helper function. We will replace the _Description_ column with this PCA representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 102)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Risk Class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.034603</td>\n",
       "      <td>0.055342</td>\n",
       "      <td>0.267891</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>0.047872</td>\n",
       "      <td>-0.052396</td>\n",
       "      <td>-0.036685</td>\n",
       "      <td>0.037355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>-0.072841</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>-0.013779</td>\n",
       "      <td>0.058944</td>\n",
       "      <td>-0.035031</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.003931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104014</td>\n",
       "      <td>-0.117345</td>\n",
       "      <td>0.024708</td>\n",
       "      <td>-0.092492</td>\n",
       "      <td>0.041033</td>\n",
       "      <td>-0.016126</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>-0.058723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026923</td>\n",
       "      <td>-0.085280</td>\n",
       "      <td>0.052192</td>\n",
       "      <td>-0.038089</td>\n",
       "      <td>0.058620</td>\n",
       "      <td>-0.012766</td>\n",
       "      <td>-0.103323</td>\n",
       "      <td>-0.044598</td>\n",
       "      <td>-0.038659</td>\n",
       "      <td>-0.010482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.064500</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>-0.005889</td>\n",
       "      <td>-0.019405</td>\n",
       "      <td>-0.014005</td>\n",
       "      <td>-0.059466</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>-0.057275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>-0.050570</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>-0.005326</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>-0.037543</td>\n",
       "      <td>0.025085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.034522</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.010737</td>\n",
       "      <td>-0.087647</td>\n",
       "      <td>0.106327</td>\n",
       "      <td>0.055582</td>\n",
       "      <td>-0.068926</td>\n",
       "      <td>-0.025874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042845</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-0.008188</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>-0.042559</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>-0.070414</td>\n",
       "      <td>0.040549</td>\n",
       "      <td>-0.050071</td>\n",
       "      <td>0.058199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>-0.038171</td>\n",
       "      <td>-0.012491</td>\n",
       "      <td>-0.018472</td>\n",
       "      <td>-0.034877</td>\n",
       "      <td>0.020534</td>\n",
       "      <td>-0.037476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091719</td>\n",
       "      <td>0.051549</td>\n",
       "      <td>0.062825</td>\n",
       "      <td>0.142490</td>\n",
       "      <td>0.149060</td>\n",
       "      <td>-0.028642</td>\n",
       "      <td>-0.049611</td>\n",
       "      <td>0.070782</td>\n",
       "      <td>-0.043804</td>\n",
       "      <td>-0.068547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID  Risk Class         0         1         2         3         4  \\\n",
       "0      30004           1 -0.034603  0.055342  0.267891  0.067528  0.047872   \n",
       "1      30101           0  0.104014 -0.117345  0.024708 -0.092492  0.041033   \n",
       "2      29801           1 -0.064500  0.006318 -0.005889 -0.019405 -0.014005   \n",
       "3      29702           2 -0.034522  0.000103 -0.010737 -0.087647  0.106327   \n",
       "4      29103           2 -0.052139 -0.007692 -0.038171 -0.012491 -0.018472   \n",
       "\n",
       "          5         6         7  ...        90        91        92        93  \\\n",
       "0 -0.052396 -0.036685  0.037355  ... -0.018118 -0.072841  0.019978  0.025398   \n",
       "1 -0.016126 -0.001712 -0.058723  ... -0.026923 -0.085280  0.052192 -0.038089   \n",
       "2 -0.059466  0.013294 -0.057275  ... -0.015907  0.000414 -0.050570  0.003069   \n",
       "3  0.055582 -0.068926 -0.025874  ...  0.042845  0.013999 -0.008188  0.007396   \n",
       "4 -0.034877  0.020534 -0.037476  ...  0.091719  0.051549  0.062825  0.142490   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.013779  0.058944 -0.035031  0.020134  0.004118  0.003931  \n",
       "1  0.058620 -0.012766 -0.103323 -0.044598 -0.038659 -0.010482  \n",
       "2  0.004267 -0.005326  0.030372  0.023704 -0.037543  0.025085  \n",
       "3 -0.042559  0.144272 -0.070414  0.040549 -0.050071  0.058199  \n",
       "4  0.149060 -0.028642 -0.049611  0.070782 -0.043804 -0.068547  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Description' in df_prototyping.columns:\n",
    "    pca_matrix, tfidf_vectorizer, pca_vectorizer = create_pca_representation(df_prototyping['Description'], 'prototype')\n",
    "    df_prototyping.drop('Description', axis=1, inplace=True)\n",
    "    df_prototyping = pd.concat([df_prototyping, pd.DataFrame(pca_matrix)], axis=1)\n",
    "\n",
    "display(df_prototyping.shape)\n",
    "df_prototyping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into a training and testing set using the `split_data()` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Output Variable Distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    593\n",
       "1    573\n",
       "0    557\n",
       "Name: Risk Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Output Variable Distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    66\n",
       "1    64\n",
       "0    62\n",
       "Name: Risk Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df_prototyping)\n",
    "\n",
    "print('Training Output Variable Distribution')\n",
    "display(y_train.value_counts())\n",
    "print()\n",
    "print('Testing Output Variable Distribution')\n",
    "display(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Modeling on Prototype\n",
    "\n",
    "Now that the data has been prepared, we are ready to try out some multi-class modeling algorithms. We will train and tune a wide gamut of modeling techniques to determine which approach (if any) most correctly and efficiently categorizes the risk of each project. As a reminder, the risk classifications are as follows:\n",
    "- `Risk Class 0`: Technical Execution Risk\n",
    "- `Risk Class 1`: Managerial Process Risk\n",
    "- `Risk Class 2`: Operational Cost Risk\n",
    "<br><br>\n",
    "\n",
    "***\n",
    "#### Logistic Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.625     0.726     0.672        62\n",
      "           1      0.806     0.781     0.794        64\n",
      "           2      0.655     0.576     0.613        66\n",
      "\n",
      "    accuracy                          0.693       192\n",
      "   macro avg      0.696     0.694     0.693       192\n",
      "weighted avg      0.696     0.693     0.692       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lm, lm_metrics = model_logisticregression_tuned(X_train, y_train, X_test, y_test)\n",
    "print(lm_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Random Forest Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "{'criterion': 'gini', 'max_depth': None, 'max_features': 0.25, 'n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.653     0.758     0.701        62\n",
      "           1      0.787     0.750     0.768        64\n",
      "           2      0.644     0.576     0.608        66\n",
      "\n",
      "    accuracy                          0.693       192\n",
      "   macro avg      0.695     0.695     0.692       192\n",
      "weighted avg      0.694     0.693     0.692       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rfc, rfc_metrics = model_randomforestclassifier_tuned(X_train, y_train, X_test, y_test)\n",
    "print(rfc_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Light Gradient Boosted Model Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "{'max_depth': 15, 'min_split_gain': 0.2, 'num_leaves': 20, 'reg_alpha': 0, 'reg_lambda': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.646     0.677     0.661        62\n",
      "           1      0.774     0.750     0.762        64\n",
      "           2      0.615     0.606     0.611        66\n",
      "\n",
      "    accuracy                          0.677       192\n",
      "   macro avg      0.679     0.678     0.678       192\n",
      "weighted avg      0.678     0.677     0.677       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lgb, lgb_metrics = model_lgbmclassifier_tuned(X_train, y_train, X_test, y_test)\n",
    "print(lgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### K Nearest Neighbors Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "{'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.570     0.726     0.638        62\n",
      "           1      0.800     0.688     0.739        64\n",
      "           2      0.552     0.485     0.516        66\n",
      "\n",
      "    accuracy                          0.630       192\n",
      "   macro avg      0.640     0.633     0.631       192\n",
      "weighted avg      0.640     0.630     0.630       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn, knn_metrics = model_knnclassifier_tuned(X_train, y_train, X_test, y_test)\n",
    "print(knn_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Gaussian Naive Bayes Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'var_smoothing': 0.11288378916846892}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.619     0.419     0.500        62\n",
      "           1      0.786     0.688     0.733        64\n",
      "           2      0.500     0.712     0.588        66\n",
      "\n",
      "    accuracy                          0.609       192\n",
      "   macro avg      0.635     0.606     0.607       192\n",
      "weighted avg      0.634     0.609     0.608       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gnb, gnb_metrics = model_gnbclassifier_tuned(X_train, y_train, X_test, y_test)\n",
    "print(gnb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Custom Ensembles\n",
    "***\n",
    "\n",
    "All of our models seem to do well in different areas of the input space. We think we can yield better results by ensembling our different models. First, we create a list of all of the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_all = [('lm', best_lm), ('rfc', best_rfc), ('lgb', best_lgb), ('knn', best_knn), ('gnb', best_gnb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used: ['lm', 'rfc', 'lgb', 'knn', 'gnb']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.645     0.645     0.645        62\n",
      "           1      0.847     0.781     0.813        64\n",
      "           2      0.606     0.652     0.628        66\n",
      "\n",
      "    accuracy                          0.693       192\n",
      "   macro avg      0.699     0.693     0.695       192\n",
      "weighted avg      0.699     0.693     0.695       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom ensemble of all of the above methods\n",
    "ensemble_all, metrics_all = custom_ensemble(estimators_all, 5, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Models used: {}'.format([x for x, y in ensemble_all.estimators]))\n",
    "print(metrics_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used: ['rfc', 'lgb', 'knn', 'gnb']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.690     0.645     0.667        62\n",
      "           1      0.836     0.797     0.816        64\n",
      "           2      0.603     0.667     0.633        66\n",
      "\n",
      "    accuracy                          0.703       192\n",
      "   macro avg      0.709     0.703     0.705       192\n",
      "weighted avg      0.709     0.703     0.705       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom ensemble with the best 4 models\n",
    "ensemble_4, metrics_4 = custom_ensemble(estimators_all, 4, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Models used: {}'.format([x for x, y in ensemble_4.estimators]))\n",
    "print(metrics_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used: ['lm', 'rfc', 'lgb']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.657     0.742     0.697        62\n",
      "           1      0.810     0.797     0.803        64\n",
      "           2      0.695     0.621     0.656        66\n",
      "\n",
      "    accuracy                          0.719       192\n",
      "   macro avg      0.721     0.720     0.719       192\n",
      "weighted avg      0.721     0.719     0.718       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom ensemble with the best 3 models\n",
    "ensemble_3, metrics_3 = custom_ensemble(estimators_all, 3, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Models used: {}'.format([x for x, y in ensemble_3.estimators]))\n",
    "print(metrics_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **Custom Ensemble: 3 Models** model has the best performance, handily beating the other individual and ensemble models.\n",
    "- All of our models perform best in predicting `Managerial Process Risk`, followed by `Technical Execution Risk` and performing worst in predicting `Operational Cost Risk`.\n",
    "- Ensembling the models generally improves performance for all of the risk categories, as expected.\n",
    "\n",
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"step-4\"></a>\n",
    "\n",
    "## Testing Augmented Inputs\n",
    "\n",
    "We will now try to augment the description of the projects to include more than the *Title* and *Abstract* features. To do so, we need to decide which of the available features can add value beyond the two we have already selected.\n",
    "\n",
    "### Prep Augmented Dataframe\n",
    "\n",
    "#### Remove Irrelevant Features\n",
    "\n",
    "First, we remove any columns containing data unavailable at the beginning of the project.\n",
    "- _Lesson(s) Learned_ was used to generate the risk classifications. Logically, we cannot use it as an input. Regardless, it is information that comes to light during the course of the project. Therefore, this column will be dropped.\n",
    "- The other columns that either relate to _Lesson(s) Learned_ or are post-facto include:\n",
    "    - _Recommendation(s)_\n",
    "    - _Date Lesson Occurred_\n",
    "    - _Driving Event_\n",
    "    - _Evidence_\n",
    "    - _The related NASA policy(s), standard(s), handbook(s), procedure(s) or other rules_\n",
    "    - _From what phase of the program or project was this lesson learned captured?_\n",
    "    - _Where (other lessons, presentations, publications, etc.)?_\n",
    "- _Publish Date_ is also a post-facto column. Furthermore, we don't expect the publication date to actually impact the risk classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Project / Program</th>\n",
       "      <th>NASA Mission Directorate(s)</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Risk Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "      <td>The purpose of this lesson is to highlight the...</td>\n",
       "      <td>LaRC</td>\n",
       "      <td>Radiation Budget Instrument</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Procurement, Small Business &amp; Industrial Relat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "      <td>Early indications show that the commercial spa...</td>\n",
       "      <td>NESC</td>\n",
       "      <td>Space Shuttle Program, Commercial Crewed Space...</td>\n",
       "      <td>Human Exploration and Operations</td>\n",
       "      <td>Public</td>\n",
       "      <td>Flight Equipment, Ground Operations, Hardware,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "      <td>Trace contaminants in high-purity hydrazine (H...</td>\n",
       "      <td>NESC</td>\n",
       "      <td>All NASA missions using high purity hydrazine ...</td>\n",
       "      <td>Human Exploration and Operations, Science, Spa...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Ground Operations, Launch Vehicle, Parts, Mate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "      <td>During the Radiological Control Center (RADCC)...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>Radiological Control Center (RADCC)</td>\n",
       "      <td>Human Exploration and Operations</td>\n",
       "      <td>Public</td>\n",
       "      <td>Engineering Design, Integration and Testing, S...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>Copper Tube Pinch Failure</td>\n",
       "      <td>While pinching copper tubes is a standard prac...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>Mass Spectrometer observing lunar operations (...</td>\n",
       "      <td>Human Exploration and Operations, Space Techno...</td>\n",
       "      <td>Public</td>\n",
       "      <td>Engineering Design, Integration and Testing, M...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID                                              Title  \\\n",
       "0      30004  Relationship of Government and Contractor Risk...   \n",
       "1      30101  Cable Harness Wiring and Connector Anomalies C...   \n",
       "2      29801  Best Practices for the Elemental Profiling of ...   \n",
       "3      29702  Integration and Dependency Between Different A...   \n",
       "4      29103                          Copper Tube Pinch Failure   \n",
       "\n",
       "                                            Abstract Organization  \\\n",
       "0  The purpose of this lesson is to highlight the...         LaRC   \n",
       "1  Early indications show that the commercial spa...         NESC   \n",
       "2  Trace contaminants in high-purity hydrazine (H...         NESC   \n",
       "3  During the Radiological Control Center (RADCC)...          KSC   \n",
       "4  While pinching copper tubes is a standard prac...          KSC   \n",
       "\n",
       "                                   Project / Program  \\\n",
       "0                        Radiation Budget Instrument   \n",
       "1  Space Shuttle Program, Commercial Crewed Space...   \n",
       "2  All NASA missions using high purity hydrazine ...   \n",
       "3                Radiological Control Center (RADCC)   \n",
       "4  Mass Spectrometer observing lunar operations (...   \n",
       "\n",
       "                         NASA Mission Directorate(s) Sensitivity  \\\n",
       "0  Aeronautics Research, Human Exploration and Op...      Public   \n",
       "1                   Human Exploration and Operations      Public   \n",
       "2  Human Exploration and Operations, Science, Spa...      Public   \n",
       "3                   Human Exploration and Operations      Public   \n",
       "4  Human Exploration and Operations, Space Techno...      Public   \n",
       "\n",
       "                                              Topics  Risk Class  \n",
       "0  Procurement, Small Business & Industrial Relat...           1  \n",
       "1  Flight Equipment, Ground Operations, Hardware,...           0  \n",
       "2  Ground Operations, Launch Vehicle, Parts, Mate...           1  \n",
       "3  Engineering Design, Integration and Testing, S...           2  \n",
       "4  Engineering Design, Integration and Testing, M...           2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented = df_master.copy()\n",
    "\n",
    "if 'Lesson(s) Learned' in df_augmented.columns:\n",
    "    df_augmented.drop(['Lesson(s) Learned', 'Recommendation(s)', 'Date Lesson Occurred', 'Driving Event', 'Evidence',\n",
    "                       'The related NASA policy(s), standard(s), handbook(s), procedure(s) or other rules',\n",
    "                       'From what phase of the program or project was this lesson learned captured?',\n",
    "                       'Where (other lessons, presentations, publications, etc.)?', 'Publish Date'], inplace=True, axis=1)\n",
    "\n",
    "display(df_augmented.shape)\n",
    "df_augmented.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Feature Analysis\n",
    "\n",
    "Next, aside from _Title_ and _Abstract_, we will try to identify which other categorical features (if any) may offer value to the text-based description of the project. We start by checking how many unique values exist for each categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Organization                    15\n",
       "Project / Program              200\n",
       "NASA Mission Directorate(s)     25\n",
       "Sensitivity                      1\n",
       "Topics                         431\n",
       "Risk Class                       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented.iloc[:,3:].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _Organization_ seems to be a straightforward categorical column that provides value and has a manageable number of distinct values. We will keep this in our analysis, but we'll append 'Org' to the front of each value so it does not get removed in our preprocessing steps.\n",
    "- _Project / Program_ doesn't seem to have a standard format for its values. Furthermore, it has 200 values for a total 2000 different projects. We think including this feature in our analysis would add too many columns for not much value. We will remove this column from analysis and try to see what our initial results look like, before considering including the text from this column in our inputs.\n",
    "- _NASA Mission Directorate(s)_ seems to be comma-separated values. There may be value in adding them into our analysis. We will need to reformat the inputs to keep track of each mission directoraate separately (e.g. changing 'Aeronautics Research' to 'Directorate_Aeronautics_Research' so our analysis will consider it one term).\n",
    "- _Sensitivity_ has only one value in the entire column. It is useless and will therefore be removed from our analysis.\n",
    "- _Topics_ seems to be similar to _NASA Mission Directorate(s)_. We will handle it similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Risk Class</th>\n",
       "      <th>Fixed Organization</th>\n",
       "      <th>Fixed Directorates</th>\n",
       "      <th>Fixed Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "      <td>The purpose of this lesson is to highlight the...</td>\n",
       "      <td>1</td>\n",
       "      <td>org_larc</td>\n",
       "      <td>directorate_aeronautics_research directorate_h...</td>\n",
       "      <td>topic_procurement topic_small_business_&amp;_indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "      <td>Early indications show that the commercial spa...</td>\n",
       "      <td>0</td>\n",
       "      <td>org_nesc</td>\n",
       "      <td>directorate_human_exploration_and_operations</td>\n",
       "      <td>topic_flight_equipment topic_ground_operations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "      <td>Trace contaminants in high-purity hydrazine (H...</td>\n",
       "      <td>1</td>\n",
       "      <td>org_nesc</td>\n",
       "      <td>directorate_human_exploration_and_operations d...</td>\n",
       "      <td>topic_ground_operations topic_launch_vehicle t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "      <td>During the Radiological Control Center (RADCC)...</td>\n",
       "      <td>2</td>\n",
       "      <td>org_ksc</td>\n",
       "      <td>directorate_human_exploration_and_operations</td>\n",
       "      <td>topic_engineering_design topic_integration_and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>Copper Tube Pinch Failure</td>\n",
       "      <td>While pinching copper tubes is a standard prac...</td>\n",
       "      <td>2</td>\n",
       "      <td>org_ksc</td>\n",
       "      <td>directorate_human_exploration_and_operations d...</td>\n",
       "      <td>topic_engineering_design topic_integration_and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID                                              Title  \\\n",
       "0      30004  Relationship of Government and Contractor Risk...   \n",
       "1      30101  Cable Harness Wiring and Connector Anomalies C...   \n",
       "2      29801  Best Practices for the Elemental Profiling of ...   \n",
       "3      29702  Integration and Dependency Between Different A...   \n",
       "4      29103                          Copper Tube Pinch Failure   \n",
       "\n",
       "                                            Abstract  Risk Class  \\\n",
       "0  The purpose of this lesson is to highlight the...           1   \n",
       "1  Early indications show that the commercial spa...           0   \n",
       "2  Trace contaminants in high-purity hydrazine (H...           1   \n",
       "3  During the Radiological Control Center (RADCC)...           2   \n",
       "4  While pinching copper tubes is a standard prac...           2   \n",
       "\n",
       "  Fixed Organization                                 Fixed Directorates  \\\n",
       "0           org_larc  directorate_aeronautics_research directorate_h...   \n",
       "1           org_nesc       directorate_human_exploration_and_operations   \n",
       "2           org_nesc  directorate_human_exploration_and_operations d...   \n",
       "3            org_ksc       directorate_human_exploration_and_operations   \n",
       "4            org_ksc  directorate_human_exploration_and_operations d...   \n",
       "\n",
       "                                        Fixed Topics  \n",
       "0  topic_procurement topic_small_business_&_indus...  \n",
       "1  topic_flight_equipment topic_ground_operations...  \n",
       "2  topic_ground_operations topic_launch_vehicle t...  \n",
       "3  topic_engineering_design topic_integration_and...  \n",
       "4  topic_engineering_design topic_integration_and...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns we decided to remove from further analysis\n",
    "if 'Project / Program' in df_augmented.columns:\n",
    "    df_augmented.drop(['Project / Program', 'Sensitivity'], axis=1, inplace=True)\n",
    "\n",
    "# modify contents of columns as described above\n",
    "def fix_column_values(text, prefix):\n",
    "    if text == 'nan':\n",
    "        return ''\n",
    "        \n",
    "    text_to_return = ''\n",
    "    text_split = text.split(',')\n",
    "    for directorate in text_split:\n",
    "        text_to_return += prefix + directorate.strip().replace(' ', '_') + ' '\n",
    "    \n",
    "    return text_to_return.strip().lower()\n",
    "\n",
    "# fix the columns, and then drop the original columns\n",
    "if 'Organization' in df_augmented.columns:\n",
    "    df_augmented['Fixed Organization'] = 'org_' + df_augmented['Organization'].astype(str).apply(str.lower)\n",
    "    df_augmented['Fixed Directorates'] = df_augmented['NASA Mission Directorate(s)'].astype(str).apply(fix_column_values, prefix='Directorate_')\n",
    "    df_augmented['Fixed Topics'] = df_augmented['Topics'].astype(str).apply(fix_column_values, prefix='Topic_')\n",
    "    df_augmented.drop(['Organization', 'NASA Mission Directorate(s)', 'Topics'], axis=1, inplace=True)\n",
    "\n",
    "display(df_augmented.shape)\n",
    "df_augmented.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine all of the features into one block of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Risk Class</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>1</td>\n",
       "      <td>Relationship of Government and Contractor Risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>0</td>\n",
       "      <td>Cable Harness Wiring and Connector Anomalies C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Practices for the Elemental Profiling of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>2</td>\n",
       "      <td>Integration and Dependency Between Different A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>2</td>\n",
       "      <td>Copper Tube Pinch Failure While pinching coppe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID  Risk Class                                        Description\n",
       "0      30004           1  Relationship of Government and Contractor Risk...\n",
       "1      30101           0  Cable Harness Wiring and Connector Anomalies C...\n",
       "2      29801           1  Best Practices for the Elemental Profiling of ...\n",
       "3      29702           2  Integration and Dependency Between Different A...\n",
       "4      29103           2  Copper Tube Pinch Failure While pinching coppe..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Title' in df_augmented.columns:\n",
    "    df_augmented['Description'] = df_augmented['Title'].astype(str) + ' ' +\\\n",
    "                                  df_augmented['Abstract'].astype(str) + ' ' +\\\n",
    "                                  df_augmented['Fixed Organization'].astype(str) + ' ' +\\\n",
    "                                  df_augmented['Fixed Directorates'].astype(str) + ' ' +\\\n",
    "                                  df_augmented['Fixed Topics'].astype(str)\n",
    "    df_augmented.drop(['Title', 'Abstract', 'Fixed Organization', 'Fixed Directorates', 'Fixed Topics'], axis=1, inplace=True)\n",
    "\n",
    "display(df_augmented.shape)\n",
    "df_augmented.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did in the prototyping phase, we will replace the _Description_ column with a PCA representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2066, 102)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lesson ID</th>\n",
       "      <th>Risk Class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30004</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.034716</td>\n",
       "      <td>-0.083590</td>\n",
       "      <td>-0.113285</td>\n",
       "      <td>-0.116456</td>\n",
       "      <td>0.187248</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.024026</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052676</td>\n",
       "      <td>-0.015712</td>\n",
       "      <td>-0.008246</td>\n",
       "      <td>-0.048921</td>\n",
       "      <td>-0.030299</td>\n",
       "      <td>-0.025052</td>\n",
       "      <td>-0.035918</td>\n",
       "      <td>-0.015953</td>\n",
       "      <td>-0.009674</td>\n",
       "      <td>-0.024879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30101</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141969</td>\n",
       "      <td>-0.014333</td>\n",
       "      <td>-0.055893</td>\n",
       "      <td>-0.038056</td>\n",
       "      <td>-0.044317</td>\n",
       "      <td>-0.131780</td>\n",
       "      <td>-0.039499</td>\n",
       "      <td>-0.026036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094513</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>-0.025125</td>\n",
       "      <td>-0.031425</td>\n",
       "      <td>-0.053176</td>\n",
       "      <td>0.043312</td>\n",
       "      <td>0.062119</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>0.026287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29801</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.059767</td>\n",
       "      <td>-0.112592</td>\n",
       "      <td>-0.042061</td>\n",
       "      <td>-0.019866</td>\n",
       "      <td>-0.045389</td>\n",
       "      <td>-0.014885</td>\n",
       "      <td>-0.018100</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006243</td>\n",
       "      <td>-0.017230</td>\n",
       "      <td>0.030369</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.027495</td>\n",
       "      <td>0.084662</td>\n",
       "      <td>0.012834</td>\n",
       "      <td>-0.079482</td>\n",
       "      <td>-0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29702</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.102526</td>\n",
       "      <td>-0.099698</td>\n",
       "      <td>-0.018568</td>\n",
       "      <td>-0.046390</td>\n",
       "      <td>-0.046420</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.045477</td>\n",
       "      <td>-0.019612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>-0.053035</td>\n",
       "      <td>-0.052721</td>\n",
       "      <td>0.049253</td>\n",
       "      <td>-0.011134</td>\n",
       "      <td>-0.009201</td>\n",
       "      <td>-0.033003</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>-0.020793</td>\n",
       "      <td>-0.027246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29103</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.079082</td>\n",
       "      <td>-0.109713</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>-0.017659</td>\n",
       "      <td>-0.050365</td>\n",
       "      <td>-0.009696</td>\n",
       "      <td>-0.028522</td>\n",
       "      <td>-0.004634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031289</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>-0.078401</td>\n",
       "      <td>-0.072140</td>\n",
       "      <td>-0.045398</td>\n",
       "      <td>0.038306</td>\n",
       "      <td>-0.019278</td>\n",
       "      <td>-0.082472</td>\n",
       "      <td>-0.024046</td>\n",
       "      <td>0.063770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lesson ID  Risk Class         0         1         2         3         4  \\\n",
       "0      30004           1 -0.034716 -0.083590 -0.113285 -0.116456  0.187248   \n",
       "1      30101           0 -0.141969 -0.014333 -0.055893 -0.038056 -0.044317   \n",
       "2      29801           1 -0.059767 -0.112592 -0.042061 -0.019866 -0.045389   \n",
       "3      29702           2 -0.102526 -0.099698 -0.018568 -0.046390 -0.046420   \n",
       "4      29103           2 -0.079082 -0.109713  0.000899 -0.017659 -0.050365   \n",
       "\n",
       "          5         6         7  ...        90        91        92        93  \\\n",
       "0  0.002583  0.024026  0.016628  ...  0.052676 -0.015712 -0.008246 -0.048921   \n",
       "1 -0.131780 -0.039499 -0.026036  ... -0.094513  0.056948 -0.025125 -0.031425   \n",
       "2 -0.014885 -0.018100  0.004954  ... -0.006243 -0.017230  0.030369  0.023033   \n",
       "3 -0.011114 -0.045477 -0.019612  ...  0.012972 -0.053035 -0.052721  0.049253   \n",
       "4 -0.009696 -0.028522 -0.004634  ...  0.031289  0.008289 -0.078401 -0.072140   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0 -0.030299 -0.025052 -0.035918 -0.015953 -0.009674 -0.024879  \n",
       "1 -0.053176  0.043312  0.062119  0.007616  0.036202  0.026287  \n",
       "2  0.000650  0.027495  0.084662  0.012834 -0.079482 -0.012737  \n",
       "3 -0.011134 -0.009201 -0.033003  0.002896 -0.020793 -0.027246  \n",
       "4 -0.045398  0.038306 -0.019278 -0.082472 -0.024046  0.063770  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Description' in df_augmented.columns:\n",
    "    pca_matrix_aug, tfidf_vectorizer_aug, pca_vectorizer_aug = create_pca_representation(df_augmented['Description'], 'augmented')\n",
    "    df_augmented.drop('Description', axis=1, inplace=True)\n",
    "    df_augmented = pd.concat([df_augmented, pd.DataFrame(pca_matrix_aug)], axis=1)\n",
    "\n",
    "display(df_augmented.shape)\n",
    "df_augmented.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into a training and testing set using the `split_data()` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Output Variable Distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    593\n",
       "1    565\n",
       "0    534\n",
       "Name: Risk Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Output Variable Distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    66\n",
       "1    63\n",
       "0    60\n",
       "Name: Risk Class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_aug, X_test_aug, y_train_aug, y_test_aug = split_data(df_augmented)\n",
    "\n",
    "print('Training Output Variable Distribution')\n",
    "display(y_train_aug.value_counts())\n",
    "print()\n",
    "print('Testing Output Variable Distribution')\n",
    "display(y_test_aug.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Modeling on Augmented Inputs\n",
    "\n",
    "We will now train and tune the same models as we tried in the prototyping phase, to see if the augmented inputs result in better model performance.\n",
    "\n",
    "***\n",
    "#### Logistic Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.597     0.717     0.652        60\n",
      "           1      0.734     0.746     0.740        63\n",
      "           2      0.585     0.470     0.521        66\n",
      "\n",
      "    accuracy                          0.640       189\n",
      "   macro avg      0.639     0.644     0.638       189\n",
      "weighted avg      0.639     0.640     0.635       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lm_aug, lm_metrics_aug = model_logisticregression_tuned(X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "print(lm_metrics_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Random Forest Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 0.25, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.625     0.667     0.645        60\n",
      "           1      0.750     0.714     0.732        63\n",
      "           2      0.585     0.576     0.580        66\n",
      "\n",
      "    accuracy                          0.651       189\n",
      "   macro avg      0.653     0.652     0.652       189\n",
      "weighted avg      0.653     0.651     0.651       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rfc_aug, rfc_metrics_aug = model_randomforestclassifier_tuned(X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "print(rfc_metrics_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Light Gradient Booosted Model Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "{'max_depth': 15, 'min_split_gain': 0, 'num_leaves': 30, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.647     0.733     0.688        60\n",
      "           1      0.710     0.778     0.742        63\n",
      "           2      0.692     0.545     0.610        66\n",
      "\n",
      "    accuracy                          0.683       189\n",
      "   macro avg      0.683     0.686     0.680       189\n",
      "weighted avg      0.684     0.683     0.679       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lgb_aug, lgb_metrics_aug = model_lgbmclassifier_tuned(X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "print(lgb_metrics_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### K Nearest Neighbors Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "{'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.529     0.600     0.562        60\n",
      "           1      0.741     0.683     0.711        63\n",
      "           2      0.540     0.515     0.527        66\n",
      "\n",
      "    accuracy                          0.598       189\n",
      "   macro avg      0.603     0.599     0.600       189\n",
      "weighted avg      0.604     0.598     0.600       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_knn_aug, knn_metrics_aug = model_knnclassifier_tuned(X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "print(knn_metrics_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Gaussian Naive Bayes Classifier\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'var_smoothing': 0.0379269019073225}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.609     0.467     0.528        60\n",
      "           1      0.788     0.651     0.713        63\n",
      "           2      0.538     0.742     0.624        66\n",
      "\n",
      "    accuracy                          0.624       189\n",
      "   macro avg      0.645     0.620     0.622       189\n",
      "weighted avg      0.644     0.624     0.623       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_gnb_aug, gnb_metrics_aug = model_gnbclassifier_tuned(X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "print(gnb_metrics_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Custom Ensembles\n",
    "***\n",
    "\n",
    "We will also try to ensemble our models like we did in the prototyping phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_all_aug = [('lm', best_lm_aug), ('rfc', best_rfc_aug), ('lgb', best_lgb_aug), ('knn', best_knn_aug), ('gnb', best_gnb_aug)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used: ['lm', 'rfc', 'lgb', 'knn', 'gnb']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.635     0.667     0.650        60\n",
      "           1      0.766     0.778     0.772        63\n",
      "           2      0.629     0.591     0.609        66\n",
      "\n",
      "    accuracy                          0.677       189\n",
      "   macro avg      0.677     0.678     0.677       189\n",
      "weighted avg      0.676     0.677     0.676       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom ensemble of all of the above methods\n",
    "ensemble_all_aug, metrics_all_aug = custom_ensemble(estimators_all_aug, 5, X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "\n",
    "print('Models used: {}'.format([x for x, y in ensemble_all_aug.estimators]))\n",
    "print(metrics_all_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used: ['lm', 'lgb', 'knn', 'gnb']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.667     0.667     0.667        60\n",
      "           1      0.778     0.778     0.778        63\n",
      "           2      0.636     0.636     0.636        66\n",
      "\n",
      "    accuracy                          0.693       189\n",
      "   macro avg      0.694     0.694     0.694       189\n",
      "weighted avg      0.693     0.693     0.693       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom ensemble with the best 4 models\n",
    "ensemble_4_aug, metrics_4_aug = custom_ensemble(estimators_all_aug, 4, X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "\n",
    "print('Models used: {}'.format([x for x, y in ensemble_4_aug.estimators]))\n",
    "print(metrics_4_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models used: ['lm', 'rfc', 'lgb']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.638     0.733     0.682        60\n",
      "           1      0.758     0.794     0.775        63\n",
      "           2      0.667     0.545     0.600        66\n",
      "\n",
      "    accuracy                          0.688       189\n",
      "   macro avg      0.687     0.691     0.686       189\n",
      "weighted avg      0.688     0.688     0.684       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom ensemble with the best 3 models\n",
    "ensemble_3_aug, metrics_3_aug = custom_ensemble(estimators_all_aug, 3, X_train_aug, y_train_aug, X_test_aug, y_test_aug)\n",
    "\n",
    "print('Models used: {}'.format([x for x, y in ensemble_3_aug.estimators]))\n",
    "print(metrics_3_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our augmented inputs result in models that perform more poorly than the original prototyped models, where the inputs were just the *Title* and the *Abstract*. This indicates that the additional features we added to our analysis are adding more noise and are failing to provide additional predictive value for risk classification. This actually is a good thing, because the prototype models are simpler and require much less data preparation.\n",
    "\n",
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"step-5\"></a>\n",
    "\n",
    "## Results and Saving Models to Project\n",
    "\n",
    "### Visualizing Results\n",
    "\n",
    "Our ensembled prototype model, **Custom Ensemble: 3 Models** model is the best performing model that we have. Let's take a look at its model metrics once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.657     0.742     0.697        62\n",
      "           1      0.810     0.797     0.803        64\n",
      "           2      0.695     0.621     0.656        66\n",
      "\n",
      "    accuracy                          0.719       192\n",
      "   macro avg      0.721     0.720     0.719       192\n",
      "weighted avg      0.721     0.719     0.718       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = ensemble_3.predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize the confusion matrix for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, pred)).plot(xticks_rotation=45, cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title('Custom Ensemble: 3 Models')\n",
    "disp.ax_.set_xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Analysis and Save Models\n",
    "\n",
    "This ensemble model has an overall accuracy, macro average F1 score, and weighted average F1 score of 72%, showing highly stable predictions across all three classes. It can categorize the potential risk of a project using just the *Title* and *Abstract* as inputs. Three of our five models (the `Logistic Regression` classifier, the `Random Forest Classifier` model, and `the Light Gradient Boosted Classifier` model) contribute to the overall ensemble's performance, resulting in better performance as a whole when compared to each individual part.\n",
    "\n",
    "To allow NASA to use this ensemble model to categorize the risk of future projects, we will now save each of these models (along with the ensembled model) to the project directory. These will be accessed by the [ClassifyRisk.py](../scripts/classify_risk.py) script. For an example of how to use this script to classify future projects, please take a look at [ClassifyRisk.ipynb](ClassifyRisk.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {'../models/model_lm.pkl': best_lm,\n",
    "               '../models/model_rfc.pkl': best_rfc,\n",
    "               '../models/model_lgb.pkl': best_lgb,\n",
    "               '../models/model_knn.pkl': best_knn,\n",
    "               '../models/model_gnb.pkl': best_gnb,\n",
    "               '../models/model_ensemble.pkl': ensemble_3}\n",
    "\n",
    "for f_name, model in models_dict.items():\n",
    "    with open(f_name, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will also need the tfidf_vectorizer and pca_vectorizer to preprocess future project descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "with open('../models/pca_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(pca_vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
