{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<a class=\"anchor\" id=\"top\"></a>\n\n# Content Based Recommendation System\n\nThis notebook creates a content-based recommendation system to calculate product similarity using the cosine-similarity method. Our recommendation system will use these cosine-similarity values to identify the most similar marker products, which in turn will identify the best question to ask at PoS."}, {"metadata": {}, "cell_type": "markdown", "source": "## Table of Contents\n\n[Step 1: Import Required Packages](#step-1) <br>\n[Step 2: Read Datasets](#step-2) <br>\n[Step 3: Data Preparation for model](#step-3) <br>\n[Step 4: Build Content Based Recommendation System](#step-4) <br>"}, {"metadata": {}, "cell_type": "markdown", "source": "<a class=\"anchor\" id=\"step-1\"></a>\n\n## Step 1: Import Required Packages"}, {"metadata": {}, "cell_type": "code", "source": "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='76c479a0-4c1c-44db-b8a2-becdfbbf3281', project_access_token='p-df8a7e5431c2264f03914c5f141281df62d590ef')\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nfrom io import BytesIO\n# import pickle\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport re\nfrom scipy import sparse\n# from pprint import pprint\n\npd.options.display.float_format = \"{:,.2f}\".format\npd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000\npd.set_option('display.max_colwidth', None)  # or 199", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "[nltk_data] Downloading package stopwords to /home/wsuser/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Required Functions"}, {"metadata": {}, "cell_type": "code", "source": "# These are the function that are used later in the notebook to clean the description of the products.\ndef _removeNonAscii(s):\n    return \"\".join(i for i in s if  ord(i)<128)\n\ndef make_lower_case(text):\n    return text.lower()\n\ndef remove_stop_words(text):\n    text = text.split()\n    stops = set(stopwords.words(\"english\"))\n    text = [w for w in text if not w in stops]\n    text = \" \".join(text)\n    return text\n\ndef remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)\n\ndef remove_punctuation(text):\n    tokenizer = RegexpTokenizer(r'\\w+')\n    text = tokenizer.tokenize(text)\n    text = \" \".join(text)\n    return text", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "[Back to the Top](#top)"}, {"metadata": {}, "cell_type": "markdown", "source": "<a class=\"anchor\" id=\"step-2\"></a>\n\n## Step 2: Read Datasets\n\n"}, {"metadata": {}, "cell_type": "code", "source": "# Read IBM_WATSON_ARTICLE_FULL dataset, include necessary columns to be extracted\ndf_article= pd.read_csv(project.get_file(\"IBM_WATSON_ARTICLE_FULL.csv\"), usecols=['ARTICLE_NO','ARTICLE_DESC'])\n\nprint('df_article shape', df_article.shape)\nprint('--------------------------------------')\ndf_article.head(2)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "df_article shape (856321, 2)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "   ARTICLE_NO                            ARTICLE_DESC\n0      748043  NFL - ST. LOUIS RAMS GET A GRIP 2 PACK\n1      748046       KDS RENEGADE 400 BOOT TAN CAMO 13", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ARTICLE_NO</th>\n      <th>ARTICLE_DESC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>748043</td>\n      <td>NFL - ST. LOUIS RAMS GET A GRIP 2 PACK</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>748046</td>\n      <td>KDS RENEGADE 400 BOOT TAN CAMO 13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Read ExtraSamples_Questions dataset, include necessary columns to be extracted\ndf_questions= pd.read_csv(project.get_file(\"QUESTION_MARKERS.csv\"), usecols=['Question','ARTICLE_NO','ARTICLE_DESC'])\n\nprint('df_questions shape', df_questions.shape)\nprint('--------------------------------------')\ndf_questions.head(2)", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "df_questions shape (40, 3)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "                                                  Question  ARTICLE_NO  \\\n0  Would you like to sign up for a pet food subscription?\u00a0     1555466   \n1  Would you like to sign up for a pet food subscription?\u00a0     1397138   \n\n                ARTICLE_DESC  \n0  ONE 4LB SM BITE BEEF/RICE  \n1  IAMS 4.4# NTRLS SENSITIVE  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>ARTICLE_NO</th>\n      <th>ARTICLE_DESC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Would you like to sign up for a pet food subscription?</td>\n      <td>1555466</td>\n      <td>ONE 4LB SM BITE BEEF/RICE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Would you like to sign up for a pet food subscription?</td>\n      <td>1397138</td>\n      <td>IAMS 4.4# NTRLS SENSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Read click purchase dataset and assign \"Purchase\" name to the new column of ClickType.\ndf_click_purchases = pd.read_csv(project.get_file(\"IBM_WATSON_CLICK_PURCHASE.csv\"))\n\nprint('df_click_purchases shape', df_click_purchases.shape)\nprint('--------------------------------------')\ndf_click_purchases.head(2)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "df_click_purchases shape (229598, 4)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "                                                     VISITOR_CLICK_ID  \\\n0  3398575622603852750_2390095112132868450_6_1616511665_1616511932_16   \n1  5561444425824395160_4824659609152105886_2_1608568403_1608569227_38   \n\n   TIME_DIM_KEY  ARTICLE_NO  SAP_BP_ID  \n0      20210323      705057  164093948  \n1      20201221      389237   76116948  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VISITOR_CLICK_ID</th>\n      <th>TIME_DIM_KEY</th>\n      <th>ARTICLE_NO</th>\n      <th>SAP_BP_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3398575622603852750_2390095112132868450_6_1616511665_1616511932_16</td>\n      <td>20210323</td>\n      <td>705057</td>\n      <td>164093948</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5561444425824395160_4824659609152105886_2_1608568403_1608569227_38</td>\n      <td>20201221</td>\n      <td>389237</td>\n      <td>76116948</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Read the VW_SALES dataset, include necessary columns to be extracted\ndf_sales = pd.read_csv(project.get_file(\"IBM_WATSON_VW_SALES.csv\"), usecols=['TIME_DIM_KEY', 'ARTICLE_NO', 'SAP_BP_ID'])\n\nprint('df_sales shape', df_sales.shape)\nprint('--------------------------------------')\ndf_sales.head(2)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "df_sales shape (21101188, 3)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "   ARTICLE_NO  TIME_DIM_KEY      SAP_BP_ID\n0      308453      20210727 417,504,379.00\n1      139852      20210727 417,504,379.00", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ARTICLE_NO</th>\n      <th>TIME_DIM_KEY</th>\n      <th>SAP_BP_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>308453</td>\n      <td>20210727</td>\n      <td>417,504,379.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>139852</td>\n      <td>20210727</td>\n      <td>417,504,379.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Read original Customer dataset\ndf_customers = pd.read_csv(project.get_file('IBM_WATSON_SALES_SAP_BP_ID.csv'))\n\n# About 1/3 of the customers are in the loyalty program. We will only focus on those customers, and remove the rest from analysis.\ndf_customers = df_customers[df_customers['LOYALTY_FLAG']=='Y']\n\n# Now, we need to see how many of the loyalty customers have clean data. We will only focus on those customers.\ndf_customers = df_customers[df_customers['CLEAN_FLAG']=='Y']\n\nprint('df_customers shape', df_customers.shape)\nprint('--------------------------------------')\ndf_customers.head(2)", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "df_customers shape (335051, 3)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "   SAP_BP_ID LOYALTY_FLAG CLEAN_FLAG\n0  167709999            Y          Y\n2  111792373            Y          Y", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAP_BP_ID</th>\n      <th>LOYALTY_FLAG</th>\n      <th>CLEAN_FLAG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>167709999</td>\n      <td>Y</td>\n      <td>Y</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111792373</td>\n      <td>Y</td>\n      <td>Y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# merge the customer data with click purchase data and include only necessary columns\ndf_click_purchases_subset = pd.merge(df_customers, df_click_purchases, how=\"inner\", on=\"SAP_BP_ID\")\ndf_click_purchases_subset = df_click_purchases_subset[['SAP_BP_ID','TIME_DIM_KEY','ARTICLE_NO']]\n\nprint('df_click_purchases_subset shape', df_click_purchases_subset.shape)\nprint('--------------------------------------')\ndf_click_purchases_subset.head(2)", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "df_click_purchases_subset shape (208238, 3)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "   SAP_BP_ID  TIME_DIM_KEY  ARTICLE_NO\n0  401162293      20210106      123047\n1   72643124      20210331      623840", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAP_BP_ID</th>\n      <th>TIME_DIM_KEY</th>\n      <th>ARTICLE_NO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>401162293</td>\n      <td>20210106</td>\n      <td>123047</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72643124</td>\n      <td>20210331</td>\n      <td>623840</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# merge the customer data with click purchase data and include only necessary columns\ndf_sales_subset = pd.merge(df_customers, df_sales, how=\"inner\", on=\"SAP_BP_ID\")\ndf_sales_subset = df_sales_subset[['SAP_BP_ID','TIME_DIM_KEY','ARTICLE_NO']]\n\nprint('df_sales_subset shape', df_sales_subset.shape)\nprint('--------------------------------------')\ndf_sales_subset.head(2)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "df_sales_subset shape (13117108, 3)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "   SAP_BP_ID  TIME_DIM_KEY  ARTICLE_NO\n0  167709999      20170828      332069\n1  167709999      20170520      841026", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAP_BP_ID</th>\n      <th>TIME_DIM_KEY</th>\n      <th>ARTICLE_NO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>167709999</td>\n      <td>20170828</td>\n      <td>332069</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>167709999</td>\n      <td>20170520</td>\n      <td>841026</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Make transactions dataframe by concatenating the purchase click dataframe with the sales data. Cast TIME_DIM_KEY to datetime type.\ndf_transactions = pd.concat([df_sales_subset, df_click_purchases_subset], axis=0)\ndf_transactions['TIME_DIM_KEY'] = pd.to_datetime(df_transactions['TIME_DIM_KEY'], format='%Y%m%d')\n\nprint('df_transactions shape', df_transactions.shape)\nprint('--------------------------------------')\ndf_transactions.head(2)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "df_transactions shape (13325346, 3)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "   SAP_BP_ID TIME_DIM_KEY  ARTICLE_NO\n0  167709999   2017-08-28      332069\n1  167709999   2017-05-20      841026", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAP_BP_ID</th>\n      <th>TIME_DIM_KEY</th>\n      <th>ARTICLE_NO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>167709999</td>\n      <td>2017-08-28</td>\n      <td>332069</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>167709999</td>\n      <td>2017-05-20</td>\n      <td>841026</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a class=\"anchor\" id=\"step-3\"></a>\n\n## Step3: Data Preparation for model"}, {"metadata": {}, "cell_type": "code", "source": "# We will only keep transactional data from the past two years\ndf_transactions['Year'] = pd.DatetimeIndex(df_transactions['TIME_DIM_KEY']).year\ndf_transactions = df_transactions.loc[(df_transactions['Year'] == 2020) | (df_transactions['Year'] == 2021)]\n\n# Merge the article description with transactional data\ndf_transactions = pd.merge(df_transactions, df_article, on=[\"ARTICLE_NO\"], how=\"inner\")\n\nprint('df_transactions shape', df_transactions.shape)\nprint('--------------------------------------')\ndf_transactions.head(2)", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "df_transactions shape (5602878, 5)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "   SAP_BP_ID TIME_DIM_KEY  ARTICLE_NO  Year         ARTICLE_DESC\n0  111792373   2021-05-06      209612  2021  FLIPPIN FISH 11.5IN\n1  182786234   2021-04-28      209612  2021  FLIPPIN FISH 11.5IN", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAP_BP_ID</th>\n      <th>TIME_DIM_KEY</th>\n      <th>ARTICLE_NO</th>\n      <th>Year</th>\n      <th>ARTICLE_DESC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>111792373</td>\n      <td>2021-05-06</td>\n      <td>209612</td>\n      <td>2021</td>\n      <td>FLIPPIN FISH 11.5IN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>182786234</td>\n      <td>2021-04-28</td>\n      <td>209612</td>\n      <td>2021</td>\n      <td>FLIPPIN FISH 11.5IN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# generate dataframe of products and their descriptions, sorted by the highest transactional volume\ndf_products = df_transactions[['ARTICLE_NO', 'ARTICLE_DESC', 'SAP_BP_ID']]\ndf_products = df_products.groupby(['ARTICLE_NO', 'ARTICLE_DESC']).count().sort_values(by='SAP_BP_ID', ascending=False).reset_index()[['ARTICLE_NO', 'ARTICLE_DESC']]\n\n# add the marker products to this dataframe\ndf_products = pd.concat([df_questions[['ARTICLE_NO', 'ARTICLE_DESC']], df_products], axis=0)\n\nprint('df_products shape', df_products.shape)\nprint('--------------------------------------')\ndf_products.head(2)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "df_products shape (55571, 2)\n--------------------------------------\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "   ARTICLE_NO               ARTICLE_DESC\n0     1555466  ONE 4LB SM BITE BEEF/RICE\n1     1397138  IAMS 4.4# NTRLS SENSITIVE", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ARTICLE_NO</th>\n      <th>ARTICLE_DESC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1555466</td>\n      <td>ONE 4LB SM BITE BEEF/RICE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1397138</td>\n      <td>IAMS 4.4# NTRLS SENSITIVE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Use the required functions that are defined above to clean the description of the products, to remove the punctuation and some unncessary symbols and add a new column to dataframe as clean description.\ndf_products['cleaned_DESC'] = df_products['ARTICLE_DESC'].apply(_removeNonAscii)\ndf_products['cleaned_DESC'] = df_products.cleaned_DESC.apply(func = remove_stop_words)\ndf_products['cleaned_DESC'] = df_products.cleaned_DESC.apply(func=remove_punctuation)\ndf_products['cleaned_DESC'] = df_products.cleaned_DESC.apply(func=remove_html)", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# project.save_data('df_products_cos_sim.csv', df_product_sorted.to_csv(index=False), overwrite=True)", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a class=\"anchor\" id=\"step-4\"></a>\n\n## Step 4: Build Content Based Recommendation System\n\nCosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis."}, {"metadata": {}, "cell_type": "code", "source": "# Here, we use TfidfVectorizer to transform text to feature vectors that can be used as inputs to the cosine-similarity estimator.\nvectorizer = TfidfVectorizer(analyzer='word', ngram_range = (1, 2), min_df = 0, stop_words = 'english')\ntfidf_matrix = vectorizer.fit_transform(df_products['cleaned_DESC'])\ntfidf_matrix.shape", "execution_count": 19, "outputs": [{"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "(55571, 126523)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Compute the cosine similarity matrix for tfidf_matrix using linear_kernel\ncosine_similarity = linear_kernel(tfidf_matrix, tfidf_matrix)\n# We compress the cosine similarity matrix into a CSR matrix to save space\ncompressed = sparse.csr_matrix(cosine_similarity)\ncompressed", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Save the cosine similarity CSR to file\n\nfilename = 'sparse_mat.npz'\nsparse.save_npz('sparse_mat.npz', compressed)\nwith open('sparse_mat.npz', 'rb') as f:\n    _ = project.save_data(filename, f, overwrite=True)", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.11", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}